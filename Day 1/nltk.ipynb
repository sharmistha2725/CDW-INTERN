{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\S\n",
      "[nltk_data]     SHARMISTHA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When Pop was a kid, all the town roads were unpaved except for Route 9,\\nthe Portland Road.', 'When I came along, only Deep Cut and Methodist Road\\nwere dirt.', 'These days, all of them are paved.', 'In the sixties there was only one\\nstore, Brownie’s, where old men sat around an actual pickle barrel.', 'Now there\\nare two or three, and a kind of downtown (if you want to call it that) on the\\nQuaker Hill Road.', 'We have a pizza joint, two beauty parlors, and—hard to\\nbelieve but true—a nail salon that seems to be a going concern.', 'No high\\nschool, though; that hasn’t changed.', 'Harlow kids have three choices: Castle\\nRock High, Gates Falls High, or Mountain View Secondary, most commonly\\nknown as the Christer Academy.', 'We’re a bunch of country bumpkins out\\nhere: pickup-driving, country-music-listening, coffee-brandy-drinking,\\nRepublican-leaning hicks from the sticks.', 'There’s nothing much to\\nrecommend us, except for two men who came from here: my pop and his\\nfriend Butch LaVerdiere.', 'Two talented bastids, as Pop put it during his brief\\nover-the-fence conversation with Ruth Crawford.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "mytext = \"\"\"When Pop was a kid, all the town roads were unpaved except for Route 9,\n",
    "the Portland Road. When I came along, only Deep Cut and Methodist Road\n",
    "were dirt. These days, all of them are paved. In the sixties there was only one\n",
    "store, Brownie’s, where old men sat around an actual pickle barrel. Now there\n",
    "are two or three, and a kind of downtown (if you want to call it that) on the\n",
    "Quaker Hill Road. We have a pizza joint, two beauty parlors, and—hard to\n",
    "believe but true—a nail salon that seems to be a going concern. No high\n",
    "school, though; that hasn’t changed. Harlow kids have three choices: Castle\n",
    "Rock High, Gates Falls High, or Mountain View Secondary, most commonly\n",
    "known as the Christer Academy. We’re a bunch of country bumpkins out\n",
    "here: pickup-driving, country-music-listening, coffee-brandy-drinking,\n",
    "Republican-leaning hicks from the sticks. There’s nothing much to\n",
    "recommend us, except for two men who came from here: my pop and his\n",
    "friend Butch LaVerdiere. Two talented bastids, as Pop put it during his brief\n",
    "over-the-fence conversation with Ruth Crawford.\"\"\"\n",
    "\n",
    "my_sentences = sent_tokenize(mytext)\n",
    "print(my_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'Pop', 'was', 'a', 'kid', ',', 'all', 'the', 'town', 'roads', 'were', 'unpaved', 'except', 'for', 'Route', '9', ',', 'the', 'Portland', 'Road', '.', 'When', 'I', 'came', 'along', ',', 'only', 'Deep', 'Cut', 'and', 'Methodist', 'Road', 'were', 'dirt', '.', 'These', 'days', ',', 'all', 'of', 'them', 'are', 'paved', '.', 'In', 'the', 'sixties', 'there', 'was', 'only', 'one', 'store', ',', 'Brownie', '’', 's', ',', 'where', 'old', 'men', 'sat', 'around', 'an', 'actual', 'pickle', 'barrel', '.', 'Now', 'there', 'are', 'two', 'or', 'three', ',', 'and', 'a', 'kind', 'of', 'downtown', '(', 'if', 'you', 'want', 'to', 'call', 'it', 'that', ')', 'on', 'the', 'Quaker', 'Hill', 'Road', '.', 'We', 'have', 'a', 'pizza', 'joint', ',', 'two', 'beauty', 'parlors', ',', 'and—hard', 'to', 'believe', 'but', 'true—a', 'nail', 'salon', 'that', 'seems', 'to', 'be', 'a', 'going', 'concern', '.', 'No', 'high', 'school', ',', 'though', ';', 'that', 'hasn', '’', 't', 'changed', '.', 'Harlow', 'kids', 'have', 'three', 'choices', ':', 'Castle', 'Rock', 'High', ',', 'Gates', 'Falls', 'High', ',', 'or', 'Mountain', 'View', 'Secondary', ',', 'most', 'commonly', 'known', 'as', 'the', 'Christer', 'Academy', '.', 'We', '’', 're', 'a', 'bunch', 'of', 'country', 'bumpkins', 'out', 'here', ':', 'pickup-driving', ',', 'country-music-listening', ',', 'coffee-brandy-drinking', ',', 'Republican-leaning', 'hicks', 'from', 'the', 'sticks', '.', 'There', '’', 's', 'nothing', 'much', 'to', 'recommend', 'us', ',', 'except', 'for', 'two', 'men', 'who', 'came', 'from', 'here', ':', 'my', 'pop', 'and', 'his', 'friend', 'Butch', 'LaVerdiere', '.', 'Two', 'talented', 'bastids', ',', 'as', 'Pop', 'put', 'it', 'during', 'his', 'brief', 'over-the-fence', 'conversation', 'with', 'Ruth', 'Crawford', '.']\n"
     ]
    }
   ],
   "source": [
    "my_words = word_tokenize(mytext)\n",
    "print(my_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PorterStemmer>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from nltk.stem import PorterStemmer\n",
    "# init stemmer\n",
    "porter_stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>connected</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>connection</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connections</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>connects</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word stemmed_word\n",
       "0       connect      connect\n",
       "1     connected      connect\n",
       "2    connection      connect\n",
       "3   connections      connect\n",
       "4      connects      connect"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem connect variations\n",
    "words=[\"connect\",\"connected\",\"connection\",\"connections\",\"connects\"]\n",
    "stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
    "\n",
    "stemdf= pd.DataFrame({'original_word': words,'stemmed_word': stemmed_words})\n",
    "stemdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\S\n",
      "[nltk_data]     SHARMISTHA\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trouble', 'troubling', 'troubled', 'troubles', 'dogs', 'cats'] ['trouble', 'trouble', 'trouble', 'trouble', 'dog', 'cat']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# init lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words=[\"trouble\",\"troubling\",\"troubled\",\"troubles\",\"dogs\", \"cats\"]\n",
    "lemmatized_words=[lemmatizer.lemmatize(word=word,pos='v') for word in words]\n",
    "print(words, lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
